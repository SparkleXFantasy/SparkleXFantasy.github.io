<!DOCTYPE html>
<html lang="en">
<!-- Template: https://github.com/luost26/academic-homepage -->
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>Publications - Xiufeng Song</title>

    <!-- Stylesheets -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.6.0/css/bootstrap.min.css" integrity="sha512-P5MgMn1jBN01asBgU0z60Qk4QxiXo86+wlFahKrsQf37c9cro517WzVSPPV1tDKzhku2iJ2FVgL67wG03SGnNA==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha512-DTOQO9RWCH3ppGqcWaEA1BIZOC6xxalwEsw9c2QQeAIftl+Vegovlnee1c9QX4TctnWMn13TZye+giMm8e2LwA==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.1/css/academicons.min.css" integrity="sha512-b1ASx0WHgVFL5ZQhTgiPWX+68KjS38Jk87jg7pe+qC7q9YkEtFq0z7xCglv7qGIs/68d3mAp+StfC8WKC5SSAg==" crossorigin="anonymous" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,300;0,400;0,700;0,900;1,300;1,400;1,700;1,900&family=Fira+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Source+Code+Pro:ital,wght@0,200..900;1,200..900&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous">
    <link rel="stylesheet" href="/homepage/assets/css/global.css">
</head>
<body class="bg-light" data-spy="scroll" data-target="#navbar-year" data-offset="100">
    <nav class="navbar navbar-expand-sm navbar-dark bg-dark fixed-top mb-5 shadow-sm">
    <div class="container-lg">
        <a class="navbar-brand"><strong>Xiufeng Song</strong></a>
        <button class="navbar-toggler" style="font-size: 1em; padding: 0.5em;" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fas fa-map"></i> Menu
        </button>

        <div class="collapse navbar-collapse" id="navbarResponsive">
            <ul class="navbar-nav ml-auto">
                
                <li class="nav-item ">
                    <a class="nav-link" href="/homepage/index_layout2">Home</a>
                </li>
                
                <li class="nav-item active">
                    <a class="nav-link" href="/homepage/publications">Publications</a>
                </li>
                
            </ul>
        </div>
    </div>
</nav>

    <div class="container-lg">
        

<div class="row">
    <div class="col-12 col-lg-10">
        
        
        <h2 class="pt-4" id="year-2025">2025</h2>
        <div class="my-0 p-0 bg-white shadow-sm rounded-xl">
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters border-bottom border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/homepage/assets/images/covers/2025-nips-viki.png" alt="Viki-r: Coordinating embodied multi-agent cooperation via reinforcement learning" class="lazy w-100 rounded-sm" style="height: 85px; object-fit: cover; max-width: 100%;" src="/homepage/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">Viki-r: Coordinating embodied multi-agent cooperation via reinforcement learning</h5>
            <p class="mt-0 mb-0 small"><span class="text-body">
            Li Kang*, </span><span class="text-body">
            <b><b>Xiufeng Song</b></b>*, </span><span class="text-body">
            Heng Zhou*, </span><span class="text-body">
            Yiran Qin, </span><span class="text-body">
            Jie Yang, </span><span class="text-body">
            Xiaohong Liu, </span><span class="text-body">
            Philip Torr, </span><span class="text-body">
            Lei Bai, </span><span class="text-body">
            Zhenfei Yin<sup>#</sup></span>
<mark>(* <i> equal contribution</i>, <sup>#</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>Neural Information Processing Systems (NeurIPS) Benchmark</i> 2025  <span data-semantic-scholar-id=""></span></p>
            <p class="mt-0 mb-0 small text-muted"></p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://arxiv.org/abs/2506.09049">[Paper]</a>
                
                
                
                <a target="_blank" href="https://github.com/MARS-EAI/VIKI-R">[Code]</a>
                
                
                
                <a target="_blank" href="https://faceong.github.io/VIKI-R/">[Page]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none border-bottom border-gray rounded-xl-top  lazy" data-src="/homepage/assets/images/covers/2025-nips-viki.png">
    <div class="w-100 rounded-xl-top " style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">Viki-r: Coordinating embodied multi-agent cooperation via reinforcement learning</h5>
                <p class="mt-0 mb-0 small"><span class="text-body">
            Li Kang*, </span><span class="text-body">
            <b><b>Xiufeng Song</b></b>*, </span><span class="text-body">
            Heng Zhou*, </span><span class="text-body">
            Yiran Qin, </span><span class="text-body">
            Jie Yang, </span><span class="text-body">
            Xiaohong Liu, </span><span class="text-body">
            Philip Torr, </span><span class="text-body">
            Lei Bai, </span><span class="text-body">
            Zhenfei Yin<sup>#</sup></span>
<mark>(* <i> equal contribution</i>, <sup>#</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>Neural Information Processing Systems (NeurIPS) Benchmark</i> 2025  <span data-semantic-scholar-id=""></span></p>
                <p class="mt-0 mb-0 small text-muted"></p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://arxiv.org/abs/2506.09049">[Paper]</a>
                    
                    
                    
                    <a target="_blank" href="https://github.com/MARS-EAI/VIKI-R">[Code]</a>
                    
                    
                    
                    <a target="_blank" href="https://faceong.github.io/VIKI-R/">[Page]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters  border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/homepage/assets/images/covers/2025-iccv-robofactory.png" alt="Robofactory: Exploring embodied agent collaboration with compositional constraints" class="lazy w-100 rounded-sm" style="height: 85px; object-fit: cover; max-width: 100%;" src="/homepage/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">Robofactory: Exploring embodied agent collaboration with compositional constraints</h5>
            <p class="mt-0 mb-0 small"><span class="text-body">
            Yiran Qin*, </span><span class="text-body">
            Li Kang*, </span><span class="text-body">
            <b><b>Xiufeng Song</b></b>*, </span><span class="text-body">
            Zhenfei Yin, </span><span class="text-body">
            Xiaohong Liu, </span><span class="text-body">
            Xihui Liu, </span><span class="text-body">
            Ruimao Zhang, </span><span class="text-body">
            Lei Bai<sup>#</sup></span>
<mark>(* <i> equal contribution</i>, <sup>#</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>International Conference on Computer Vision (ICCV)</i> 2025  <span class="badge badge-pill badge-publication badge-success">Best Paper Award at CVPR 2025 MEIS Workshop</span> <span data-semantic-scholar-id=""></span></p>
            <p class="mt-0 mb-0 small text-muted"></p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://arxiv.org/abs/2503.16408">[Paper]</a>
                
                
                
                <a target="_blank" href="https://github.com/MARS-EAI/RoboFactory">[Code]</a>
                
                
                
                <a target="_blank" href="https://iranqin.github.io/robofactory/">[Page]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none  border-gray  rounded-xl-bottom lazy" data-src="/homepage/assets/images/covers/2025-iccv-robofactory.png">
    <div class="w-100  rounded-xl-bottom" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">Robofactory: Exploring embodied agent collaboration with compositional constraints</h5>
                <p class="mt-0 mb-0 small"><span class="text-body">
            Yiran Qin*, </span><span class="text-body">
            Li Kang*, </span><span class="text-body">
            <b><b>Xiufeng Song</b></b>*, </span><span class="text-body">
            Zhenfei Yin, </span><span class="text-body">
            Xiaohong Liu, </span><span class="text-body">
            Xihui Liu, </span><span class="text-body">
            Ruimao Zhang, </span><span class="text-body">
            Lei Bai<sup>#</sup></span>
<mark>(* <i> equal contribution</i>, <sup>#</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>International Conference on Computer Vision (ICCV)</i> 2025  <span class="badge badge-pill badge-publication badge-success">Best Paper Award at CVPR 2025 MEIS Workshop</span> <span data-semantic-scholar-id=""></span></p>
                <p class="mt-0 mb-0 small text-muted"></p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://arxiv.org/abs/2503.16408">[Paper]</a>
                    
                    
                    
                    <a target="_blank" href="https://github.com/MARS-EAI/RoboFactory">[Code]</a>
                    
                    
                    
                    <a target="_blank" href="https://iranqin.github.io/robofactory/">[Page]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
        </div>
        
        
        <h2 class="pt-4" id="year-2024">2024</h2>
        <div class="my-0 p-0 bg-white shadow-sm rounded-xl">
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters border-bottom border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/homepage/assets/images/covers/2024-cvpr-unistd.png" alt="UniSTD: Towards Unified Spatio-Temporal Learning across Diverse Disciplines" class="lazy w-100 rounded-sm" style="height: 85px; object-fit: cover; max-width: 100%;" src="/homepage/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">UniSTD: Towards Unified Spatio-Temporal Learning across Diverse Disciplines</h5>
            <p class="mt-0 mb-0 small"><span class="text-body">
            Chen Tang, </span><span class="text-body">
            Xinzhu Ma, </span><span class="text-body">
            Encheng Su, </span><span class="text-body">
            <b><b>Xiufeng Song</b></b>, </span><span class="text-body">
            Xiaohong Liu, </span><span class="text-body">
            Wei-Hong Li, </span><span class="text-body">
            Lei Bai, </span><span class="text-body">
            Wanli Ouyang, </span><span class="text-body">
            Xiangyu Yue<sup>#</sup></span>
<mark>(<sup>#</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>Computer Vision and Pattern Recognition Conference (CVPR)</i> 2024  <span data-semantic-scholar-id=""></span></p>
            <p class="mt-0 mb-0 small text-muted"></p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://arxiv.org/abs/2503.20748">[Paper]</a>
                
                
                
                <a target="_blank" href="https://github.com/1hunters/UniSTD">[Code]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none border-bottom border-gray rounded-xl-top  lazy" data-src="/homepage/assets/images/covers/2024-cvpr-unistd.png">
    <div class="w-100 rounded-xl-top " style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">UniSTD: Towards Unified Spatio-Temporal Learning across Diverse Disciplines</h5>
                <p class="mt-0 mb-0 small"><span class="text-body">
            Chen Tang, </span><span class="text-body">
            Xinzhu Ma, </span><span class="text-body">
            Encheng Su, </span><span class="text-body">
            <b><b>Xiufeng Song</b></b>, </span><span class="text-body">
            Xiaohong Liu, </span><span class="text-body">
            Wei-Hong Li, </span><span class="text-body">
            Lei Bai, </span><span class="text-body">
            Wanli Ouyang, </span><span class="text-body">
            Xiangyu Yue<sup>#</sup></span>
<mark>(<sup>#</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>Computer Vision and Pattern Recognition Conference (CVPR)</i> 2024  <span data-semantic-scholar-id=""></span></p>
                <p class="mt-0 mb-0 small text-muted"></p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://arxiv.org/abs/2503.20748">[Paper]</a>
                    
                    
                    
                    <a target="_blank" href="https://github.com/1hunters/UniSTD">[Code]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters border-bottom border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/homepage/assets/images/covers/2024-cvpr-m2f2.png" alt="Rethinking Vision-Language Model in Face Forensics: Multi-Modal Interpretable Forged Face Detector" class="lazy w-100 rounded-sm" style="height: 85px; object-fit: cover; max-width: 100%;" src="/homepage/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">Rethinking Vision-Language Model in Face Forensics: Multi-Modal Interpretable Forged Face Detector</h5>
            <p class="mt-0 mb-0 small"><span class="text-body">
            Xiao Guo, </span><span class="text-body">
            <b><b>Xiufeng Song</b></b>, </span><span class="text-body">
            Yue Zhang, </span><span class="text-body">
            Xiaohong Liu, </span><span class="text-body">
            Xiaoming Liu<sup>#</sup></span>
<mark>(<sup>#</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>Computer Vision and Pattern Recognition Conference (CVPR)</i> 2024  <span class="badge badge-pill badge-publication badge-success">Oral</span> <span data-semantic-scholar-id=""></span></p>
            <p class="mt-0 mb-0 small text-muted"></p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://arxiv.org/abs/2503.20188">[Paper]</a>
                
                
                
                <a target="_blank" href="https://github.com/CHELSEA234/M2F2_Det">[Code]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none border-bottom border-gray   lazy" data-src="/homepage/assets/images/covers/2024-cvpr-m2f2.png">
    <div class="w-100  " style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">Rethinking Vision-Language Model in Face Forensics: Multi-Modal Interpretable Forged Face Detector</h5>
                <p class="mt-0 mb-0 small"><span class="text-body">
            Xiao Guo, </span><span class="text-body">
            <b><b>Xiufeng Song</b></b>, </span><span class="text-body">
            Yue Zhang, </span><span class="text-body">
            Xiaohong Liu, </span><span class="text-body">
            Xiaoming Liu<sup>#</sup></span>
<mark>(<sup>#</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>Computer Vision and Pattern Recognition Conference (CVPR)</i> 2024  <span class="badge badge-pill badge-publication badge-success">Oral</span> <span data-semantic-scholar-id=""></span></p>
                <p class="mt-0 mb-0 small text-muted"></p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://arxiv.org/abs/2503.20188">[Paper]</a>
                    
                    
                    
                    <a target="_blank" href="https://github.com/CHELSEA234/M2F2_Det">[Code]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters  border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/homepage/assets/images/covers/2024-nips-mmdet.png" alt="On learning multi-modal forgery representation for diffusion generated video detection" class="lazy w-100 rounded-sm" style="height: 85px; object-fit: cover; max-width: 100%;" src="/homepage/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">On learning multi-modal forgery representation for diffusion generated video detection</h5>
            <p class="mt-0 mb-0 small"><span class="text-body">
            <b><b>Xiufeng Song</b></b>, </span><span class="text-body">
            Xiao Guo, </span><span class="text-body">
            Jiache Zhang, </span><span class="text-body">
            Qirui Li, </span><span class="text-body">
            Lei Bai, </span><span class="text-body">
            Xiaoming Liu, </span><span class="text-body">
            Guangtao Zhai, </span><span class="text-body">
            Xiaohong Liu<sup>#</sup></span>
<mark>(<sup>#</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>Neural Information Processing Systems (NeurIPS)</i> 2024  <span data-semantic-scholar-id=""></span></p>
            <p class="mt-0 mb-0 small text-muted"></p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://arxiv.org/abs/2410.23623">[Paper]</a>
                
                
                
                <a target="_blank" href="https://github.com/SparkleXFantasy/MM-Det">[Code]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none  border-gray  rounded-xl-bottom lazy" data-src="/homepage/assets/images/covers/2024-nips-mmdet.png">
    <div class="w-100  rounded-xl-bottom" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">On learning multi-modal forgery representation for diffusion generated video detection</h5>
                <p class="mt-0 mb-0 small"><span class="text-body">
            <b><b>Xiufeng Song</b></b>, </span><span class="text-body">
            Xiao Guo, </span><span class="text-body">
            Jiache Zhang, </span><span class="text-body">
            Qirui Li, </span><span class="text-body">
            Lei Bai, </span><span class="text-body">
            Xiaoming Liu, </span><span class="text-body">
            Guangtao Zhai, </span><span class="text-body">
            Xiaohong Liu<sup>#</sup></span>
<mark>(<sup>#</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>Neural Information Processing Systems (NeurIPS)</i> 2024  <span data-semantic-scholar-id=""></span></p>
                <p class="mt-0 mb-0 small text-muted"></p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://arxiv.org/abs/2410.23623">[Paper]</a>
                    
                    
                    
                    <a target="_blank" href="https://github.com/SparkleXFantasy/MM-Det">[Code]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
        </div>
        
    </div>

    <div class="col-2 d-none d-lg-block">
        <div id="navbar-year" class="nav nav-pills flex-column sticky-top" style="top: 80px">
            
            <a class="nav-link d-block" href="#year-2025">2025</a>
            
            <a class="nav-link d-block" href="#year-2024">2024</a>
            
        </div>
    </div>

</div>

    </div>
    <footer class="footer border-top py-2 mt-5 bg-white small">
    <div class="container-lg">
        <div class="row my-3">
            <div class="col-6">
                <div class="text-muted">
                    <i>Last updated: Dec 2025</i>
                </div>
            </div>
            <div class="col-6">
                <div class="text-right text-muted">
                    <a href="https://github.com/luost26/academic-homepage" target="_blank"><i class="fas fa-pencil-ruler"></i> academic-homepage</a>
                </div>
            </div>
        </div>
    </div>
</footer>


    <!-- Scripts -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery.lazy/1.7.9/jquery.lazy.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.6.0/js/bootstrap.min.js" integrity="sha512-XKa9Hemdy1Ui3KSGgJdgMyYlUg1gM+QhL6cnlyTe2qzMCYm4nAZ1PsVerQzTTXzonUR+dmswHqgJPuwCq1MaAg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/github-buttons/2.14.2/buttons.min.js" integrity="sha512-OYwZx04hKFeFNYrWxIyo3atgGpb+cxU0ENWBZs72X7T9U+NoHPM1ftUn/Mfw7dRDXrqWA6M1wBg6z6fGE32aeA==" crossorigin="anonymous"></script>
    <script src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
    <script src="https://unpkg.com/imagesloaded@5/imagesloaded.pkgd.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
              delimiters: [
                  {left: '$$', right: '$$', display: true},
                  {left: '$', right: '$', display: false}
              ],
              throwOnError : false
            });
        });
    </script>
    <script src="/homepage/assets/js/common.js"></script>
    <script src="/homepage/assets/js/bubble_visual_hash.js"></script>
    <script src="/homepage/assets/js/semantic_scholar_citation_count.js"></script>
</body>
</html>
